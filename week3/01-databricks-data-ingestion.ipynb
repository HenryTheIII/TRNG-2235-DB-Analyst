{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "001cb229-aadd-4f43-82b0-923be5ab32e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Delta Lake & Data Ingestion\n",
    "\n",
    "- Getting data into databricks is comonly called data ingestion.\n",
    "- data engineers or data warehouse managers are primarily responsible for data ingestion.\n",
    "\n",
    "### Delta Lake\n",
    "\n",
    "![delta lake](./images/delta-lake.png)\n",
    "\n",
    "- the goal of data ingestion is to bring in files and data from external data sourceslike cloud storage and sql tables inro Delta Lake as Delta tabels.\n",
    "- Delta Lake is an open-source protocol that databricks uses for the data layer.\n",
    "\n",
    "\n",
    "### Delta Table\n",
    "\n",
    "\n",
    "- Delta tables store data within a folder directory. Within that directory the data is stored as **Parquet files** .\n",
    "- Delta adds delta logs that are stored as JSON files alogside the parquet files.\n",
    "- delta logs keep track of all transactions on data and table versions.\n",
    "- table states are maintained using the transaction logs. If data is inserted, deleted or updated in the table, Delta adds a transaction (log file) and the table stays updated and managed.\n",
    "\n",
    "- The transaction log provides:\n",
    "\n",
    "  - **ACID transactions** (atomicity, consistency, isolation, durability) for concurrent reads/writes.\n",
    "  - **Table versioning** enabling **time travel** (querying historical data).\n",
    "  \n",
    "\n",
    "### Key Features of Delta Lake\n",
    "\n",
    "* ACID transaction support for safe concurrent operations.\n",
    "* DML operations (INSERT, UPDATE, DELETE, MERGE).\n",
    "* Time travel to query or restore previous versions.\n",
    "* Schema enforcement and evolution.\n",
    "* Unified batch and streaming support.\n",
    "* Optimizations and scalability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36cb1f26-0ff3-4930-b784-91400159ff04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "USE CATALOG workspace;\n",
    "USE SCHEMA `2235-wk3`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee9ddcc-9798-41bc-804d-96a43dd5f7d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffc65044-c722-4cfa-9097-48be5fe81def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Common Data Importing Methods for Data Analysts:**\n",
    "\n",
    "- File Upload UI\n",
    "\n",
    "- CTAS (Creat table as Select)\n",
    "\n",
    "- COPY INTO \n",
    "\n",
    "- FROM read_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa067dc-357a-46ef-a0b0-a69c932a6665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Ingestion with CTAS and read_files() - BATCH Ingestion\n",
    "\n",
    "- `CREATE TABLE AS (CTAS)` is used to create and populate tables using the results of a query.\n",
    "- `read_files()` table-valued function enebles reading data of various file formats and provides additional options for data ingestion.\n",
    "\n",
    "**Documentation:**\n",
    "\n",
    "- [read_files](https://docs.databricks.com/aws/en/sql/language-manual/functions/read_files)\n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- a `_rescued_data` column is automatically added to capture any data that does not match the inferred schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "614a51c5-d9c9-4637-a3e4-f02eda90fbca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh \n",
    "\n",
    "ls /Volumes/workspace/2235-wk3/orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075bb248-2e1d-4afa-acee-9056b9b325c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM csv.`/Volumes/workspace/2235-wk3/orders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604c7f29-1d32-435d-8e6c-030192a20921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM \n",
    "\n",
    "read_files(\n",
    "\n",
    "  '/Volumes/workspace/2235-wk3/orders',\n",
    "  format => 'csv',\n",
    "  inferSchema => 'true',\n",
    "  header => 'true',\n",
    "  escape => '\"'\n",
    ") LIMIT  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0443c094-bc77-4677-a9f9-03721234dd7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE orders_bronze\n",
    "USING DELTA -- optional\n",
    "SELECT * FROM \n",
    "read_files(\n",
    "\n",
    "  '/Volumes/workspace/2235-wk3/orders',\n",
    "  format => 'csv',\n",
    "  inferSchema => 'true',\n",
    "  header => 'true',\n",
    "  escape => '\"'\n",
    ");\n",
    "\n",
    "-- preview the table\n",
    "\n",
    "SELECT * FROM orders_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfc8b54-ad34-4bd9-aba4-bbdf4e7feace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE TABLE orders_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb10c0e6-064a-4e48-b2f0-26b7a3bb923a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE TABLE EXTENDED orders_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75c085af-d416-4679-8c36-74be5bfe909c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### tabels\n",
    "\n",
    "- managed table - UC manages everything; even cloud storage.\n",
    "  - discards metadata and deletes the associated data when table is dropped\n",
    "  - format is delta\n",
    "  - comes with new features, performance, simplicity, stricter access\n",
    "- external table - external cloud location\n",
    "  - discards meteadata. does not dete the data\n",
    "  - the path specified bt the `LOCATION` keyword\n",
    "  - manually manages\n",
    "  - format can be DELTA, CSV, JSON, AVRO, and PARQUET etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f05cbf6-af70-435d-8a2c-9799f46a2069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "  customer_id VARCHAR(10) PRIMARY KEY,\n",
    "  first_name VARCHAR(50),\n",
    "  last_name VARCHAR(50),\n",
    "  email VARCHAR(100),\n",
    "  signup_date DATE,\n",
    "  country VARCHAR(50),\n",
    "  is_active BOOLEAN\n",
    ")\n",
    "LOCATION 's3://db-external-storage-orders-2235/output/';\n",
    "\n",
    "-- Insert customer records\n",
    "INSERT INTO customers (customer_id, first_name, last_name, email, signup_date, country, is_active) VALUES\n",
    "('CU-7D31', 'Alice', 'Johnson', 'alice.johnson@email.com', '2022-01-15', 'USA', TRUE),\n",
    "('CU-9A52', 'Bob', 'Smith', 'bob.smith@email.com', '2023-03-22', 'USA', TRUE),\n",
    "('CU-2L68', 'Carol', 'Davis', 'carol.davis@email.com', '2021-07-30', 'Canada', TRUE),\n",
    "('CU-4E93', 'David', 'Lee', 'david.lee@email.com', '2020-11-05', 'UK', FALSE),\n",
    "('CU-1B75', 'Emma', 'Wilson', 'emma.wilson@email.com', '2019-09-14', 'USA', TRUE),\n",
    "('CU-8F42', 'Frank', 'Taylor', 'frank.taylor@email.com', '2023-01-20', 'Canada', TRUE),\n",
    "('CU-6K17', 'Grace', 'Martinez', 'grace.martinez@email.com', '2022-05-09', 'UK', TRUE),\n",
    "('CU-3R84', 'Henry', 'Anderson', 'henry.anderson@email.com', '2021-12-11', 'USA', TRUE),\n",
    "('CU-5N26', 'Irene', 'Thomas', 'irene.thomas@email.com', '2020-08-23', 'Canada', FALSE),\n",
    "('CU-9L73', 'Jack', 'Moore', 'jack.moore@email.com', '2023-06-04', 'USA', TRUE),\n",
    "('CU-2M35', 'Karen', 'Jackson', 'karen.jackson@email.com', '2021-04-16', 'UK', TRUE),\n",
    "('CU-4T89', 'Leo', 'White', 'leo.white@email.com', '2022-10-30', 'USA', TRUE);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "395c818d-cd95-4978-97ed-f5551b52129b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DROP TABLE IF EXISTS customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184bf166-23a0-469f-b11b-94177e1dbc45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "df = (spark.read.format(\"csv\").load(\"/Volumes/workspace/2235-wk3/orders\", header = True, inferSchema = True, escape = '\"'))\n",
    "\n",
    "(df.write.mode(\"overwrite\").saveAsTable(\"orders_bronze_py\"))\n",
    "\n",
    "orders_bronze = spark.table(\"orders_bronze_py\")\n",
    "\n",
    "orders_bronze.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9712f00c-5f5f-472c-b370-424ac23ec560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Data Ingestion using COPY INTO - Incremental data ingestion\n",
    "\n",
    "- `COPY INTO` allows to load data from a file location into Delta table. \n",
    "- re-triable and idempotent.\n",
    "- new files in source location are added and files already loaded are skipped.\n",
    "\n",
    "**Documentation**\n",
    "\n",
    "[COPY INTO](https://docs.databricks.com/aws/en/sql/language-manual/delta-copy-into)\n",
    "\n",
    "\n",
    "- `mergeSchema` copy option is used for schema evolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d313f609-9da0-485b-8f86-60b6d7ab9343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DROP TABLE IF EXISTS orders_bronze_ci;\n",
    "CREATE TABLE orders_bronze_ci;\n",
    "\n",
    "COPY INTO orders_bronze_ci\n",
    "FROM '/Volumes/workspace/2235-wk3/orders'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'escape' = '\"')\n",
    "COPY_OPTIONS ('mergeSchema' = 'true');\n",
    "\n",
    "\n",
    "SELECT * FROM orders_bronze_ci;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc0cc97-6109-4400-8465-112c3e74e223",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754937753113}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "COPY INTO orders_bronze_ci\n",
    "FROM '/Volumes/workspace/2235-wk3/orders'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'escape' = '\"')\n",
    "COPY_OPTIONS ('mergeSchema' = 'true');\n",
    "\n",
    "\n",
    "-- SELECT * FROM orders_bronze_ci;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d40493c-b481-4bad-9452-5c673a9b7007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Feature/Method                | File Upload UI                                | CTAS (Create Table As Select)                            | COPY INTO                                      | Auto Loader                                                  |\n",
    "| ----------------------------- | --------------------------------------------- | -------------------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------ |\n",
    "| **Purpose**                   | Upload files manually via Databricks UI       | Create a new table by selecting data from a query        | Load data from external files into a table     | Automatically ingest new files from a cloud storage location |\n",
    "| **Data Source**               | Local files from user’s machine               | Query result or existing tables                          | External files (e.g., CSV, JSON, Parquet)      | Files landing in cloud storage (e.g., Azure Blob, S3)        |\n",
    "| **Automation**                | Manual via UI                                 | Manual or scripted                                       | Manual or scripted                             | Fully automated continuous ingestion                         |\n",
    "| **Use Case**                  | Ad hoc, small-scale uploads                   | Quick table creation from existing data or query results | Bulk loading or incremental loading from files | Large scale, incremental ingestion of new files              |\n",
    "| **Supports Schema Evolution** | No                                            | No (schema fixed at creation)                            | Yes (with schema update options)               | Yes (infers schema, can evolve schema)                       |\n",
    "| **Performance**               | Limited by manual upload size and user action | Efficient for creating tables from existing data         | Optimized for bulk file loading                | Optimized for streaming/append scenarios                     |\n",
    "| **Data Format Support**       | Any file supported by Databricks UI upload    | Any data readable by SQL (tables, views, etc.)           | Common file formats: CSV, JSON, Parquet, etc.  | Common cloud storage file formats (CSV, JSON, Parquet, Avro) |\n",
    "| **Incremental Loading**       | No                                            | No                                                       | Yes, supports loading new files incrementally  | Yes, continuous detection of new files                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7c1b1bd-6401-4f1e-bbe1-1fdad830234b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6721217452831257,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-databricks-data-ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
